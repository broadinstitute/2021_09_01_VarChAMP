{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect NaN features at each processing step\n",
    "**Author:** Jessica Ewald <br>\n",
    "\n",
    "Inspect the features that become NaNs at each step of the single cell processing pipeline: raw profiles, well position correction, MAD normalization, cell count regression. \n",
    "\n",
    "Currently, since many analytical methods cannot handle missing values (mAP, PCA, etc), I am dropping any feature that has even a single NaN after each step. \n",
    "\n",
    "I want to know if the dropped features are random or overrepresented in some categories such that filtering them out would lose key information. If whole categories of features are being lost, then it may be necessary to devise an imputation strategy or even to modify the processing functions (ie. MAD, cell count regression) to better handle edge cases that are currently resulting in many NaNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=False,\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all paths and files\n",
    "map_data_dir = pathlib.Path(\"/dgx1nas1/storage/data/jess/varchamp/sc_data/map_data/\").resolve(strict=True)\n",
    "bl_path = pathlib.Path(f'{map_data_dir}/bl_map_data.parquet')\n",
    "well_path = pathlib.Path(f'{map_data_dir}/well_map_data.parquet')\n",
    "norm_path = pathlib.Path(f'{map_data_dir}/norm_map_data.parquet')\n",
    "cc_path = pathlib.Path(f'{map_data_dir}/cc_map_data.parquet')\n",
    "\n",
    "# Read in data\n",
    "bl = pl.read_parquet(bl_path)\n",
    "well = pl.read_parquet(well_path)\n",
    "norm = pl.read_parquet(norm_path)\n",
    "cc = pl.read_parquet(cc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feats in each matrix\n",
    "def get_feats(df):\n",
    "    feats = [i for i in df.columns if \"Metadata_\" not in i] \n",
    "    feats = [i for i in feats if i not in ['n_pos_pairs', 'n_total_pairs', 'average_precision']]\n",
    "    return feats\n",
    "    \n",
    "feats_bl = get_feats(bl)\n",
    "feats_well = get_feats(well)\n",
    "feats_norm = get_feats(norm)\n",
    "feats_cc = get_feats(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw feats (before initial NaN filter) using different approach\n",
    "raw = pl.scan_parquet(\"/dgx1nas1/storage/data/jess/varchamp/sc_data/processed_profiles/B1A1R1_annotated.parquet\")\n",
    "feats_raw = [i for i in raw.columns if \"Metadata_\" not in i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 features had at least one NaN in the raw profiles. 0, 44, and 591 additional features contained at least some NaNs after well position correction, MAD, and cell count regression respectively.\n"
     ]
    }
   ],
   "source": [
    "# Count number of features after each step (NaNs always filtered out)\n",
    "num_raw = len(feats_raw)\n",
    "num_bl = len(feats_bl)\n",
    "num_well = len(feats_well)\n",
    "num_norm = len(feats_norm)\n",
    "num_cc = len(feats_cc)\n",
    "\n",
    "print(f'{num_raw - num_bl} features had at least one NaN in the raw profiles. {num_bl - num_well}, {num_well - num_norm}, and {num_norm - num_cc} additional features contained at least some NaNs after well position correction, MAD, and cell count regression respectively.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features with at least some NaNs in the raw profiles contained only a small number of NaNs (ie. for <1% of cells). The features with NaNs after MAD and CC were missing for the entire column. Not showing these steps here to avoid reading large dataframes into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features with NaNs at each step\n",
    "nan_bl = np.setdiff1d(np.array(feats_raw), np.array(feats_bl))\n",
    "nan_norm = np.setdiff1d(np.array(feats_bl), np.array(feats_norm))\n",
    "nan_cc = np.setdiff1d(np.array(feats_norm), np.array(feats_cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, parse each feature name to obtain information on the compartment, feature type, channel, etc. Store this information in dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CP feature parse function\n",
    "def parse_cp_features(\n",
    "    feature: str, channels: list = [\"DNA\", \"RNA\", \"AGP\", \"Mito\", \"ER\", \"mito_tubeness\"]\n",
    "):\n",
    "    \"\"\"Parses a CellProfiler feature string into its semantic components.\n",
    "\n",
    "    This function will take a feature string and return a dictionary containing its semantic components,\n",
    "    specifically: the compartment, feature group, feature type, and channel.\n",
    "    If the feature string is not in a recognized format, the function will assign 'Unknown' to the non-comprehensible components.\n",
    "    Channel information will be returned as 'None' where it's not applicable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature : str\n",
    "        The CellProfiler feature string to parse.\n",
    "\n",
    "    channels : list, optional\n",
    "        A list of channel names to use when parsing the feature string. The default is ['DNA', 'RNA', 'AGP', 'Mito', 'ER', \"mito_tubeness\"].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with the following keys: 'feature', 'compartment', 'feature_group', 'feature_type', 'channel'.\n",
    "        Each key maps to the respective component of the feature string.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raised if the input is not a string.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(feature, str):\n",
    "        raise ValueError(f\"Expected a string, got {type(feature).__name__}\")\n",
    "\n",
    "    if not isinstance(channels, list):\n",
    "        raise ValueError(f\"Expected a list, got {type(channels).__name__}\")\n",
    "\n",
    "    def channel_standardizer(channel):\n",
    "        channel = channel.replace(\"Orig\", \"\")\n",
    "        return channel\n",
    "\n",
    "    unique_token = \"XUNIQUEX\"\n",
    "    tokenized_feature = feature\n",
    "    for channel in channels:\n",
    "        tokenized_channel = channel.replace(\"_\", unique_token)\n",
    "        tokenized_feature = tokenized_feature.replace(channel, tokenized_channel)\n",
    "\n",
    "    parts = tokenized_feature.split(\"_\")\n",
    "\n",
    "    feature_group = parts[1]\n",
    "    if parts[0] not in [\"Cells\", \"Cytoplasm\", \"Nuclei\", \"Image\"]:\n",
    "        compartment = \"XUNKNOWN\"\n",
    "        feature_group = \"XUNKNOWN\"\n",
    "        feature_type = \"XUNKNOWN\"\n",
    "        channel = \"XUNKNOWN\"\n",
    "    else:\n",
    "        compartment = parts[0]\n",
    "        feature_group = parts[1]\n",
    "        feature_type = \"XNONE\"  # default value\n",
    "        channel = \"XNONE\"  # default value\n",
    "\n",
    "        if feature_group in [\n",
    "            \"AreaShape\",\n",
    "            \"Neighbors\",\n",
    "            \"Children\",\n",
    "            \"Parent\",\n",
    "            \"Number\",\n",
    "            \"Threshold\",\n",
    "            \"ObjectSkeleton\",\n",
    "        ]:\n",
    "            # Examples:\n",
    "            # Cells,AreaShape,Zernike_2_0\n",
    "            # Cells,AreaShape,BoundingBoxArea\n",
    "            # Cells,Neighbors,AngleBetweenNeighbors_Adjacent\n",
    "            # Nuclei,Children,Cytoplasm_Count\n",
    "            # Nuclei,Parent,NucleiIncludingEdges\n",
    "            # Nuclei,Number,ObjectNumber\n",
    "            # Image,Threshold,SumOfEntropies_NucleiIncludingEdges\n",
    "            # Nuclei,ObjectSkeleton,NumberTrunks_mito_skel\n",
    "\n",
    "            feature_type = parts[2]\n",
    "\n",
    "        elif feature_group == \"Location\":\n",
    "            # Examples:\n",
    "            # Cells,Location_CenterMassIntensity_X_DNA\n",
    "            # Cells,Location_Center_X\n",
    "\n",
    "            feature_type = parts[2]\n",
    "            if feature_type != \"Center\":\n",
    "                channel = parts[4]\n",
    "\n",
    "        elif feature_group == \"Count\":\n",
    "            # Examples:\n",
    "            # Cells,Count,Cells\n",
    "            pass\n",
    "\n",
    "        elif feature_group == \"Granularity\":\n",
    "            # Examples:\n",
    "            # Cells,Granularity,15_ER\n",
    "            channel = parts[3]\n",
    "\n",
    "        elif feature_group in [\"Intensity\", \"ImageQuality\"]:\n",
    "            # Examples:\n",
    "            # Cells,Intensity,MeanIntensity_DNA\n",
    "            # Image,ImageQuality,MaxIntensity_OrigAGP\n",
    "            feature_type = parts[2]\n",
    "            channel = parts[3]\n",
    "\n",
    "        elif feature_group == \"Correlation\":\n",
    "            # Examples:\n",
    "            # Cells,Correlation,Correlation_DNA_ER\n",
    "            feature_type = parts[2]\n",
    "            channel = [parts[3], parts[4]]\n",
    "            channel.sort()\n",
    "            channel = \"_\".join(channel)\n",
    "\n",
    "        elif feature_group in [\"Texture\", \"RadialDistribution\"]:\n",
    "            # Examples:\n",
    "            # Cells,Texture,SumEntropy_ER_3_01_256\n",
    "            # Cells,RadialDistribution,FracAtD_mito_tubeness_2of16\n",
    "            feature_type = parts[2]\n",
    "            channel = parts[3]\n",
    "\n",
    "        else:\n",
    "            feature_group = \"XUNKNOWN\"\n",
    "            feature_type = \"XUNKNOWN\"\n",
    "            channel = \"XUNKNOWN\"\n",
    "\n",
    "    channel = \"_\".join(list(map(channel_standardizer, channel.split(\"_\"))))\n",
    "\n",
    "    channel = channel.replace(unique_token, \"_\")\n",
    "\n",
    "    return {\n",
    "        \"feature\": feature,\n",
    "        \"compartment\": compartment,\n",
    "        \"feature_group\": feature_group,\n",
    "        \"feature_type\": feature_type,\n",
    "        \"channel\": channel,\n",
    "    }\n",
    "    \n",
    "    \n",
    "def parse_feat_list(feats, channels):\n",
    "    parsed = []\n",
    "    for feat in feats:\n",
    "        parsed.append(parse_cp_features(feature = feat, channels = channels))\n",
    "    \n",
    "    return pd.DataFrame(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the feature descriptors for each list\n",
    "channels = [\"DNA\", \"GFP\", \"AGP\", \"Mito\", \"mito_tubeness\"]\n",
    "\n",
    "# all features produced by CellProfiler (universe)\n",
    "parsed_all = parse_feat_list(feats_raw, channels)\n",
    "parsed_bl = parse_feat_list(feats_bl, channels)\n",
    "parsed_norm = parse_feat_list(feats_norm, channels)\n",
    "\n",
    "# NaNs induced at each step\n",
    "parsed_nan_bl = parse_feat_list(list(nan_bl), channels)\n",
    "parsed_nan_norm = parse_feat_list(list(nan_norm), channels)\n",
    "parsed_nan_cc = parse_feat_list(list(nan_cc), channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have dataframes with the compartment, feature group, feature type, and channel of each feature that becomes a NaN at each step. However, it's hard to tell whether certain groups are overrepresented just by looking at them: it depends on the prevalence of each group in the full dataset. We can use a hypergeometric test to compute a p-value for each item within each column of the parsed NaN feature dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_overlap(df_hits, df_universe):\n",
    "\n",
    "    res = []\n",
    "\n",
    "    compartment = df_hits['compartment'].unique()\n",
    "    feature_group = df_hits['feature_group'].unique()\n",
    "    feature_type = df_hits['feature_type'].unique()\n",
    "    channel = df_hits['channel'].unique()\n",
    "\n",
    "    # M = universe size\n",
    "    # n = set size\n",
    "    # N = total hit number\n",
    "    # x = set hit number\n",
    "    \n",
    "    M = df_universe.shape[0]\n",
    "    N = df_hits.shape[0]\n",
    "\n",
    "    for feat in compartment:\n",
    "        n = df_universe['compartment'].str.count(feat).sum()\n",
    "        x = df_hits['compartment'].str.count(feat).sum()\n",
    "\n",
    "        # compute probability of drawing x or more hits (use inverse cdf = sf, at x-1)\n",
    "        prb = hypergeom.sf(x-1, M, n, N)\n",
    "        res.append({\n",
    "            \"column\": 'compartment',\n",
    "            \"value\": feat,\n",
    "            \"pval\": prb,\n",
    "            \"expected_hits\": (n/M)*N,\n",
    "            \"actual_hits\": x,\n",
    "            \"set_size\": n,\n",
    "        })\n",
    "    \n",
    "    for feat in feature_group:\n",
    "        n = df_universe['feature_group'].str.count(feat).sum()\n",
    "        x = df_hits['feature_group'].str.count(feat).sum()\n",
    "\n",
    "        prb = hypergeom.sf(x-1, M, n, N)\n",
    "        res.append({\n",
    "            \"column\": 'feature_group',\n",
    "            \"value\": feat,\n",
    "            \"pval\": prb,\n",
    "            \"expected_hits\": (n/M)*N,\n",
    "            \"actual_hits\": x,\n",
    "            \"set_size\": n,\n",
    "        })\n",
    "        \n",
    "    for feat in feature_type:\n",
    "        n = df_universe['feature_type'].str.count(feat).sum()\n",
    "        x = df_hits['feature_type'].str.count(feat).sum()\n",
    "\n",
    "        prb = hypergeom.sf(x-1, M, n, N)\n",
    "        res.append({\n",
    "            \"column\": 'feature_type',\n",
    "            \"value\": feat,\n",
    "            \"pval\": prb,\n",
    "            \"expected_hits\": (n/M)*N,\n",
    "            \"actual_hits\": x,\n",
    "            \"set_size\": n,\n",
    "        })\n",
    "        \n",
    "    for feat in channel:\n",
    "        n = df_universe['channel'].str.count(feat).sum()\n",
    "        x = df_hits['channel'].str.count(feat).sum()\n",
    "\n",
    "        prb = hypergeom.sf(x-1, M, n, N)\n",
    "        res.append({\n",
    "            \"column\": 'channel',\n",
    "            \"value\": feat,\n",
    "            \"pval\": prb,\n",
    "            \"expected_hits\": (n/M)*N,\n",
    "            \"actual_hits\": x,\n",
    "            \"set_size\": n,\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the probability (p-value) of randomly drawing the number of observed \"hits\" or more, to see if any compartment, feature type, channel, etc is overrepresented in the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, compute overlap p-values for each list of NaN feature annotations relative to the lists of all features annotations in the immediately upstream data\n",
    "nan_ora_bl = quantify_overlap(parsed_nan_bl, parsed_all)\n",
    "nan_ora_norm = quantify_overlap(parsed_nan_norm, parsed_bl)\n",
    "nan_ora_cc = quantify_overlap(parsed_nan_cc, parsed_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are highly significant p-values in every case, indicating that specific feature types/compartments etc are being converted to NaNs in non-random ways. While Jupyter will only print top 20 rows, we can still see some informative examples in the first 20 rows of the baseline vs. raw profiles (baseline data has been filtered to remove any columns with NaNs in the CellProfiler profiles).\n",
    "\n",
    "If there are still surviving features in each category that are correlated with the filtered features this may not be a huge issue, however here we can see that sometimes an entire category is filtered out (ie. rows 6-11: all of the Costes, K, Overlap, AngleBetweenNeighbors, FirstClosestDistance, and SecondClosestDistance features are lost).\n",
    "\n",
    "Full dataframes can be examined after running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>value</th>\n",
       "      <th>pval</th>\n",
       "      <th>expected_hits</th>\n",
       "      <th>actual_hits</th>\n",
       "      <th>set_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compartment</td>\n",
       "      <td>Cells</td>\n",
       "      <td>9.999859e-01</td>\n",
       "      <td>60.032571</td>\n",
       "      <td>36</td>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>compartment</td>\n",
       "      <td>Cytoplasm</td>\n",
       "      <td>6.651057e-13</td>\n",
       "      <td>59.111494</td>\n",
       "      <td>104</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>compartment</td>\n",
       "      <td>Nuclei</td>\n",
       "      <td>9.999139e-01</td>\n",
       "      <td>53.855935</td>\n",
       "      <td>33</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_group</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>1.094518e-74</td>\n",
       "      <td>9.752584</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_group</td>\n",
       "      <td>Neighbors</td>\n",
       "      <td>5.480469e-07</td>\n",
       "      <td>1.137801</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_group</td>\n",
       "      <td>RadialDistribution</td>\n",
       "      <td>9.787108e-15</td>\n",
       "      <td>31.533354</td>\n",
       "      <td>74</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>Costes</td>\n",
       "      <td>6.340333e-48</td>\n",
       "      <td>1.950517</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>K</td>\n",
       "      <td>6.340333e-48</td>\n",
       "      <td>1.950517</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>Overlap</td>\n",
       "      <td>6.797711e-24</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>AngleBetweenNeighbors</td>\n",
       "      <td>1.564523e-04</td>\n",
       "      <td>0.162543</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>FirstClosestDistance</td>\n",
       "      <td>1.564523e-04</td>\n",
       "      <td>0.162543</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>SecondClosestDistance</td>\n",
       "      <td>1.564523e-04</td>\n",
       "      <td>0.162543</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>FracAtD</td>\n",
       "      <td>2.328177e-12</td>\n",
       "      <td>10.511118</td>\n",
       "      <td>37</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_type</td>\n",
       "      <td>MeanFrac</td>\n",
       "      <td>2.328177e-12</td>\n",
       "      <td>10.511118</td>\n",
       "      <td>37</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>channel</td>\n",
       "      <td>AGP_DNA</td>\n",
       "      <td>4.268117e-12</td>\n",
       "      <td>1.625431</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>channel</td>\n",
       "      <td>AGP_GFP</td>\n",
       "      <td>4.268117e-12</td>\n",
       "      <td>1.625431</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>channel</td>\n",
       "      <td>AGP_Mito</td>\n",
       "      <td>4.268117e-12</td>\n",
       "      <td>1.625431</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>channel</td>\n",
       "      <td>DNA_GFP</td>\n",
       "      <td>4.268117e-12</td>\n",
       "      <td>1.625431</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>channel</td>\n",
       "      <td>DNA_Mito</td>\n",
       "      <td>4.268117e-12</td>\n",
       "      <td>1.625431</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>channel</td>\n",
       "      <td>GFP_Mito</td>\n",
       "      <td>4.268117e-12</td>\n",
       "      <td>1.625431</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>channel</td>\n",
       "      <td>XNONE</td>\n",
       "      <td>1.681850e-01</td>\n",
       "      <td>6.230817</td>\n",
       "      <td>9</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>channel</td>\n",
       "      <td>mito_tubeness</td>\n",
       "      <td>4.842474e-44</td>\n",
       "      <td>12.028187</td>\n",
       "      <td>74</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column                  value          pval  expected_hits  \\\n",
       "0     compartment                  Cells  9.999859e-01      60.032571   \n",
       "1     compartment              Cytoplasm  6.651057e-13      59.111494   \n",
       "2     compartment                 Nuclei  9.999139e-01      53.855935   \n",
       "3   feature_group            Correlation  1.094518e-74       9.752584   \n",
       "4   feature_group              Neighbors  5.480469e-07       1.137801   \n",
       "5   feature_group     RadialDistribution  9.787108e-15      31.533354   \n",
       "6    feature_type                 Costes  6.340333e-48       1.950517   \n",
       "7    feature_type                      K  6.340333e-48       1.950517   \n",
       "8    feature_type                Overlap  6.797711e-24       0.975258   \n",
       "9    feature_type  AngleBetweenNeighbors  1.564523e-04       0.162543   \n",
       "10   feature_type   FirstClosestDistance  1.564523e-04       0.162543   \n",
       "11   feature_type  SecondClosestDistance  1.564523e-04       0.162543   \n",
       "12   feature_type                FracAtD  2.328177e-12      10.511118   \n",
       "13   feature_type               MeanFrac  2.328177e-12      10.511118   \n",
       "14        channel                AGP_DNA  4.268117e-12       1.625431   \n",
       "15        channel                AGP_GFP  4.268117e-12       1.625431   \n",
       "16        channel               AGP_Mito  4.268117e-12       1.625431   \n",
       "17        channel                DNA_GFP  4.268117e-12       1.625431   \n",
       "18        channel               DNA_Mito  4.268117e-12       1.625431   \n",
       "19        channel               GFP_Mito  4.268117e-12       1.625431   \n",
       "20        channel                  XNONE  1.681850e-01       6.230817   \n",
       "21        channel          mito_tubeness  4.842474e-44      12.028187   \n",
       "\n",
       "    actual_hits  set_size  \n",
       "0            36      1108  \n",
       "1           104      1091  \n",
       "2            33       994  \n",
       "3            90       180  \n",
       "4             9        21  \n",
       "5            74       582  \n",
       "6            36        36  \n",
       "7            36        36  \n",
       "8            18        18  \n",
       "9             3         3  \n",
       "10            3         3  \n",
       "11            3         3  \n",
       "12           37       194  \n",
       "13           37       194  \n",
       "14           15        30  \n",
       "15           15        30  \n",
       "16           15        30  \n",
       "17           15        30  \n",
       "18           15        30  \n",
       "19           15        30  \n",
       "20            9       115  \n",
       "21           74       222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter will only print the first 20 rows, but still enough to see some important patterns\n",
    "display(nan_ora_bl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varchamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
