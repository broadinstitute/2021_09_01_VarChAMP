{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run mAP line-by-line\n",
    "**Author:** Jessica Ewald <br>\n",
    "\n",
    "The purpose of this script is to run through mAP line-by-line for a few cells that return a mAP of 1 to try understand why this happens. Code chunks will be copied from the copairs repo to accomplish this. \n",
    "\n",
    "The first step is to choose some cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import black\n",
    "import jupyter_black\n",
    "jupyter_black.load(\n",
    "    lab=False,\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# copairs imports\n",
    "import itertools\n",
    "import copairs as cps\n",
    "from copairs.matching import Matcher\n",
    "from copairs import compute\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are copies of all of the internal copairs functions that are not exported, but that are needed to compute average precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions here\n",
    "\n",
    "def prep_for_map(df_path: str, map_cols: [str], sample_col: [str], sample_n: int = 5): # type: ignore\n",
    "\n",
    "    # define filters\n",
    "    q = pl.scan_parquet(df_path).filter(\n",
    "        (pl.col(\"Metadata_node_type\") != \"TC\") &  # remove transfection controls\n",
    "        (pl.col(\"Metadata_node_type\") != \"NC\") &\n",
    "        (pl.col(\"Metadata_node_type\") != \"PC\") &\n",
    "        (pl.col(\"Metadata_node_type\") != \"CC\") &\n",
    "        (pl.col(\"Metadata_allele\") != \"_NA\") & \n",
    "        (pl.sum_horizontal(pl.col(map_cols).is_null()) == 0)  # remove any row with missing values for selected meta columns\n",
    "        ).with_columns(pl.concat_str(sample_col).alias('Metadata_samplecol'))\n",
    "    \n",
    "    # if a sample column name was provided, randomly sample sample_n rows from each column category\n",
    "    if sample_col:\n",
    "        q = q.filter(pl.int_range(0, pl.len()).shuffle().over('Metadata_samplecol') < sample_n)\n",
    "    \n",
    "    # different data frames for metadata and profiling data\n",
    "    map_cols_id = map_cols.copy()\n",
    "    map_cols_id.append(\"Metadata_CellID\")\n",
    "    meta_cols = q.select(map_cols_id)\n",
    "    meta_df = meta_cols.collect().to_pandas()\n",
    "\n",
    "    feat_col = [i for i in q.columns if \"Metadata_\" not in i] \n",
    "    q = q.select(feat_col)\n",
    "    feat_df = q.collect().to_pandas()\n",
    "\n",
    "    map_input = {'meta': meta_df, 'feats': feat_df}\n",
    "\n",
    "    return map_input\n",
    "\n",
    "def flatten_str_list(*args):\n",
    "    \"\"\"create a single list with all the params given\"\"\"\n",
    "    columns = set()\n",
    "    for col in args:\n",
    "        if isinstance(col, str):\n",
    "            columns.add(col)\n",
    "        elif isinstance(col, dict):\n",
    "            columns.update(itertools.chain.from_iterable(col.values()))\n",
    "        else:\n",
    "            columns.update(col)\n",
    "    columns = list(columns)\n",
    "    return columns\n",
    "\n",
    "def evaluate_and_filter(df, columns) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"Evaluate the query and filter the dataframe\"\"\"\n",
    "    parsed_cols = []\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            parsed_cols.append(col)\n",
    "            continue\n",
    "\n",
    "        column_names = re.findall(r\"(\\w+)\\s*[=<>!]+\", col)\n",
    "        valid_column_names = [col for col in column_names if col in df.columns]\n",
    "        if not valid_column_names:\n",
    "            raise ValueError(f\"Invalid query or column name: {col}\")\n",
    "\n",
    "        try:\n",
    "            df = df.query(col)\n",
    "            parsed_cols.extend(valid_column_names)\n",
    "        except:\n",
    "            raise ValueError(f\"Invalid query expression: {col}\")\n",
    "\n",
    "    return df, parsed_cols\n",
    "\n",
    "def build_rank_lists(pos_pairs, neg_pairs, pos_sims, neg_sims):\n",
    "    labels = np.concatenate(\n",
    "        [\n",
    "            np.ones(pos_pairs.size, dtype=np.int32),\n",
    "            np.zeros(neg_pairs.size, dtype=np.int32),\n",
    "        ]\n",
    "    )\n",
    "    ix = np.concatenate([pos_pairs.ravel(), neg_pairs.ravel()])\n",
    "    sim_all = np.concatenate([np.repeat(pos_sims, 2), np.repeat(neg_sims, 2)])\n",
    "    ix_sort = np.lexsort([1 - sim_all, ix])\n",
    "    rel_k_list = labels[ix_sort]\n",
    "    paired_ix, counts = np.unique(ix, return_counts=True)\n",
    "    return paired_ix, rel_k_list, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for accessing data\n",
    "batch_name = 'B1A1R1'\n",
    "data_dir = pathlib.Path(\"/dgx1nas1/storage/data/jess/varchamp/sc_data/processed_profiles\").resolve(strict=True)\n",
    "anno_cellID = pathlib.Path(data_dir / f\"{batch_name}_annotated_cellID.parquet\")\n",
    "\n",
    "# Set paramters for mAP\n",
    "pos_sameby = ['Metadata_allele']\n",
    "pos_diffby = ['Metadata_Plate']\n",
    "neg_sameby = ['Metadata_Plate']\n",
    "neg_diffby = ['Metadata_allele']\n",
    "batch_size = 20000\n",
    "sample_n_cells = 5\n",
    "sample_neg = True\n",
    "map_cols = list(set(pos_sameby + pos_diffby + neg_sameby + neg_diffby))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data (filter, sample, & format)\n",
    "map_input = prep_for_map(anno_cellID, map_cols, ['Metadata_Well', 'Metadata_Plate'], sample_n_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map inputs\n",
    "meta = map_input['meta']\n",
    "feats = map_input['feats'].values\n",
    "sample_factor = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"average_precision\" function starts here. It is broken down into chunks. Some extra plots etc are added to further investigate the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format inputs & define matcher\n",
    "columns = flatten_str_list(pos_sameby, pos_diffby, neg_sameby, neg_diffby)\n",
    "meta = meta.reset_index(drop=True).copy()\n",
    "\n",
    "matcher = Matcher(*evaluate_and_filter(meta, columns), seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute positive pair indices\n",
    "pos_pairs = matcher.get_all_pairs(sameby=pos_sameby, diffby=pos_diffby)\n",
    "pos_total = sum(len(p) for p in pos_pairs.values())\n",
    "\n",
    "pos_pairs = np.fromiter(\n",
    "    itertools.chain.from_iterable(pos_pairs.values()),\n",
    "    dtype=np.dtype((np.int32, 2)),\n",
    "    count=pos_total,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute negative pair indices\n",
    "neg_pairs = matcher.get_all_pairs(sameby=neg_sameby, diffby=neg_diffby)\n",
    "neg_total = sum(len(p) for p in neg_pairs.values())\n",
    "neg_pairs = np.fromiter(\n",
    "    itertools.chain.from_iterable(neg_pairs.values()),\n",
    "    dtype=np.dtype((np.int32, 2)),\n",
    "    count=neg_total,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if sample_neg, randomly sample negative pairs\n",
    "if sample_neg:\n",
    "    sample_size = pos_pairs.shape[0]*sample_factor\n",
    "    if sample_size < neg_pairs.shape[0]:\n",
    "        sampled_rows = np.random.choice(neg_pairs.shape[0], size=sample_size, replace=False)\n",
    "        neg_pairs = neg_pairs[sampled_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the next steps, I should further filter the pos & neg pairs to focus on a few examples where AP equals one and where AP equals something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute positive cosine distances\n",
    "pos_sims = compute.pairwise_cosine(feats, pos_pairs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute negative cosine distances\n",
    "neg_sims = compute.pairwise_cosine(feats, neg_pairs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ranked lists\n",
    "paired_ix, rel_k_list, counts = build_rank_lists(\n",
    "    pos_pairs, neg_pairs, pos_sims, neg_sims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average precision\n",
    "ap_scores, null_confs = compute.ap_contiguous(rel_k_list, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate metadata with results\n",
    "meta[\"n_pos_pairs\"] = 0\n",
    "meta[\"n_total_pairs\"] = 0\n",
    "meta.loc[paired_ix, \"average_precision\"] = ap_scores\n",
    "meta.loc[paired_ix, \"n_pos_pairs\"] = null_confs[:, 0]\n",
    "meta.loc[paired_ix, \"n_total_pairs\"] = null_confs[:, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varchamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
